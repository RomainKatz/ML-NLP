{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import (\n",
    "    StringIndexer, Tokenizer, StopWordsRemover, CountVectorizer, IDF, VectorAssembler\n",
    ")\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import (\n",
    "    LogisticRegression, RandomForestClassifier, DecisionTreeClassifier, NaiveBayes\n",
    ")\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"TP_Part_One\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.text(\"smsspamcollection/SMSSpamCollection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|ham\\tGo until jur...|\n",
      "|ham\\tOk lar... Jo...|\n",
      "|spam\\tFree entry ...|\n",
      "|ham\\tU dun say so...|\n",
      "|ham\\tNah I don't ...|\n",
      "|spam\\tFreeMsg Hey...|\n",
      "|ham\\tEven my brot...|\n",
      "|ham\\tAs per your ...|\n",
      "|spam\\tWINNER!! As...|\n",
      "|spam\\tHad your mo...|\n",
      "|ham\\tI'm gonna be...|\n",
      "|spam\\tSIX chances...|\n",
      "|spam\\tURGENT! You...|\n",
      "|ham\\tI've been se...|\n",
      "|ham\\tI HAVE A DAT...|\n",
      "|spam\\tXXXMobileMo...|\n",
      "|ham\\tOh k...i'm w...|\n",
      "|ham\\tEh u remembe...|\n",
      "|ham\\tFine if that...|\n",
      "|spam\\tEngland v M...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split value in two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumn(\"label\", split(data[\"value\"], \"\\t\").getItem(0)) \\\n",
    "           .withColumn(\"message\", split(data[\"value\"], \"\\t\").getItem(1)) \\\n",
    "           .drop(\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|             message|\n",
      "+-----+--------------------+\n",
      "|  ham|Go until jurong p...|\n",
      "|  ham|Ok lar... Joking ...|\n",
      "| spam|Free entry in 2 a...|\n",
      "|  ham|U dun say so earl...|\n",
      "|  ham|Nah I don't think...|\n",
      "| spam|FreeMsg Hey there...|\n",
      "|  ham|Even my brother i...|\n",
      "|  ham|As per your reque...|\n",
      "| spam|WINNER!! As a val...|\n",
      "| spam|Had your mobile 1...|\n",
      "|  ham|I'm gonna be home...|\n",
      "| spam|SIX chances to wi...|\n",
      "| spam|URGENT! You have ...|\n",
      "|  ham|I've been searchi...|\n",
      "|  ham|I HAVE A DATE ON ...|\n",
      "| spam|XXXMobileMovieClu...|\n",
      "|  ham|Oh k...i'm watchi...|\n",
      "|  ham|Eh u remember how...|\n",
      "|  ham|Fine if thats th...|\n",
      "| spam|England v Macedon...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert labels into numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"label\", outputCol=\"labelIndex\")\n",
    "data = indexer.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----------+\n",
      "|label|             message|labelIndex|\n",
      "+-----+--------------------+----------+\n",
      "|  ham|Go until jurong p...|       0.0|\n",
      "|  ham|Ok lar... Joking ...|       0.0|\n",
      "| spam|Free entry in 2 a...|       1.0|\n",
      "|  ham|U dun say so earl...|       0.0|\n",
      "|  ham|Nah I don't think...|       0.0|\n",
      "| spam|FreeMsg Hey there...|       1.0|\n",
      "|  ham|Even my brother i...|       0.0|\n",
      "|  ham|As per your reque...|       0.0|\n",
      "| spam|WINNER!! As a val...|       1.0|\n",
      "| spam|Had your mobile 1...|       1.0|\n",
      "|  ham|I'm gonna be home...|       0.0|\n",
      "| spam|SIX chances to wi...|       1.0|\n",
      "| spam|URGENT! You have ...|       1.0|\n",
      "|  ham|I've been searchi...|       0.0|\n",
      "|  ham|I HAVE A DATE ON ...|       0.0|\n",
      "| spam|XXXMobileMovieClu...|       1.0|\n",
      "|  ham|Oh k...i'm watchi...|       0.0|\n",
      "|  ham|Eh u remember how...|       0.0|\n",
      "|  ham|Fine if thats th...|       0.0|\n",
      "| spam|England v Macedon...|       1.0|\n",
      "+-----+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize text messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"message\", outputCol=\"words\")\n",
    "data = tokenizer.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----------+--------------------+\n",
      "|label|             message|labelIndex|               words|\n",
      "+-----+--------------------+----------+--------------------+\n",
      "|  ham|Go until jurong p...|       0.0|[go, until, juron...|\n",
      "|  ham|Ok lar... Joking ...|       0.0|[ok, lar..., joki...|\n",
      "| spam|Free entry in 2 a...|       1.0|[free, entry, in,...|\n",
      "|  ham|U dun say so earl...|       0.0|[u, dun, say, so,...|\n",
      "|  ham|Nah I don't think...|       0.0|[nah, i, don't, t...|\n",
      "| spam|FreeMsg Hey there...|       1.0|[freemsg, hey, th...|\n",
      "|  ham|Even my brother i...|       0.0|[even, my, brothe...|\n",
      "|  ham|As per your reque...|       0.0|[as, per, your, r...|\n",
      "| spam|WINNER!! As a val...|       1.0|[winner!!, as, a,...|\n",
      "| spam|Had your mobile 1...|       1.0|[had, your, mobil...|\n",
      "|  ham|I'm gonna be home...|       0.0|[i'm, gonna, be, ...|\n",
      "| spam|SIX chances to wi...|       1.0|[six, chances, to...|\n",
      "| spam|URGENT! You have ...|       1.0|[urgent!, you, ha...|\n",
      "|  ham|I've been searchi...|       0.0|[i've, been, sear...|\n",
      "|  ham|I HAVE A DATE ON ...|       0.0|[i, have, a, date...|\n",
      "| spam|XXXMobileMovieClu...|       1.0|[xxxmobilemoviecl...|\n",
      "|  ham|Oh k...i'm watchi...|       0.0|[oh, k...i'm, wat...|\n",
      "|  ham|Eh u remember how...|       0.0|[eh, u, remember,...|\n",
      "|  ham|Fine if thats th...|       0.0|[fine, if, thats...|\n",
      "| spam|England v Macedon...|       1.0|[england, v, mace...|\n",
      "+-----+--------------------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "data = stop_words_remover.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----------+--------------------+--------------------+\n",
      "|label|             message|labelIndex|               words|      filtered_words|\n",
      "+-----+--------------------+----------+--------------------+--------------------+\n",
      "|  ham|Go until jurong p...|       0.0|[go, until, juron...|[go, jurong, poin...|\n",
      "|  ham|Ok lar... Joking ...|       0.0|[ok, lar..., joki...|[ok, lar..., joki...|\n",
      "| spam|Free entry in 2 a...|       1.0|[free, entry, in,...|[free, entry, 2, ...|\n",
      "|  ham|U dun say so earl...|       0.0|[u, dun, say, so,...|[u, dun, say, ear...|\n",
      "|  ham|Nah I don't think...|       0.0|[nah, i, don't, t...|[nah, think, goes...|\n",
      "| spam|FreeMsg Hey there...|       1.0|[freemsg, hey, th...|[freemsg, hey, da...|\n",
      "|  ham|Even my brother i...|       0.0|[even, my, brothe...|[even, brother, l...|\n",
      "|  ham|As per your reque...|       0.0|[as, per, your, r...|[per, request, 'm...|\n",
      "| spam|WINNER!! As a val...|       1.0|[winner!!, as, a,...|[winner!!, valued...|\n",
      "| spam|Had your mobile 1...|       1.0|[had, your, mobil...|[mobile, 11, mont...|\n",
      "|  ham|I'm gonna be home...|       0.0|[i'm, gonna, be, ...|[gonna, home, soo...|\n",
      "| spam|SIX chances to wi...|       1.0|[six, chances, to...|[six, chances, wi...|\n",
      "| spam|URGENT! You have ...|       1.0|[urgent!, you, ha...|[urgent!, won, 1,...|\n",
      "|  ham|I've been searchi...|       0.0|[i've, been, sear...|[searching, right...|\n",
      "|  ham|I HAVE A DATE ON ...|       0.0|[i, have, a, date...|[date, sunday, wi...|\n",
      "| spam|XXXMobileMovieClu...|       1.0|[xxxmobilemoviecl...|[xxxmobilemoviecl...|\n",
      "|  ham|Oh k...i'm watchi...|       0.0|[oh, k...i'm, wat...|[oh, k...i'm, wat...|\n",
      "|  ham|Eh u remember how...|       0.0|[eh, u, remember,...|[eh, u, remember,...|\n",
      "|  ham|Fine if thats th...|       0.0|[fine, if, thats...|[fine, thats, wa...|\n",
      "| spam|England v Macedon...|       1.0|[england, v, mace...|[england, v, mace...|\n",
      "+-----+--------------------+----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Term frequency vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(inputCol=\"filtered_words\", outputCol=\"rawFeatures\")\n",
    "cv_model = cv.fit(data)\n",
    "data = cv_model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----------+--------------------+--------------------+--------------------+\n",
      "|label|             message|labelIndex|               words|      filtered_words|         rawFeatures|\n",
      "+-----+--------------------+----------+--------------------+--------------------+--------------------+\n",
      "|  ham|Go until jurong p...|       0.0|[go, until, juron...|[go, jurong, poin...|(13464,[7,11,31,6...|\n",
      "|  ham|Ok lar... Joking ...|       0.0|[ok, lar..., joki...|[ok, lar..., joki...|(13464,[0,24,300,...|\n",
      "| spam|Free entry in 2 a...|       1.0|[free, entry, in,...|[free, entry, 2, ...|(13464,[2,13,19,3...|\n",
      "|  ham|U dun say so earl...|       0.0|[u, dun, say, so,...|[u, dun, say, ear...|(13464,[0,69,80,1...|\n",
      "|  ham|Nah I don't think...|       0.0|[nah, i, don't, t...|[nah, think, goes...|(13464,[36,134,31...|\n",
      "| spam|FreeMsg Hey there...|       1.0|[freemsg, hey, th...|[freemsg, hey, da...|(13464,[10,67,140...|\n",
      "|  ham|Even my brother i...|       0.0|[even, my, brothe...|[even, brother, l...|(13464,[10,53,102...|\n",
      "|  ham|As per your reque...|       0.0|[as, per, your, r...|[per, request, 'm...|(13464,[127,185,4...|\n",
      "| spam|WINNER!! As a val...|       1.0|[winner!!, as, a,...|[winner!!, valued...|(13464,[1,46,121,...|\n",
      "| spam|Had your mobile 1...|       1.0|[had, your, mobil...|[mobile, 11, mont...|(13464,[0,1,13,27...|\n",
      "|  ham|I'm gonna be home...|       0.0|[i'm, gonna, be, ...|[gonna, home, soo...|(13464,[18,43,117...|\n",
      "| spam|SIX chances to wi...|       1.0|[six, chances, to...|[six, chances, wi...|(13464,[8,16,37,8...|\n",
      "| spam|URGENT! You have ...|       1.0|[urgent!, you, ha...|[urgent!, won, 1,...|(13464,[13,30,46,...|\n",
      "|  ham|I've been searchi...|       0.0|[i've, been, sear...|[searching, right...|(13464,[39,95,221...|\n",
      "|  ham|I HAVE A DATE ON ...|       0.0|[i, have, a, date...|[date, sunday, wi...|(13464,[555,1793,...|\n",
      "| spam|XXXMobileMovieClu...|       1.0|[xxxmobilemoviecl...|[xxxmobilemoviecl...|(13464,[30,109,11...|\n",
      "|  ham|Oh k...i'm watchi...|       0.0|[oh, k...i'm, wat...|[oh, k...i'm, wat...|(13464,[82,214,44...|\n",
      "|  ham|Eh u remember how...|       0.0|[eh, u, remember,...|[eh, u, remember,...|(13464,[0,2,49,13...|\n",
      "|  ham|Fine if thats th...|       0.0|[fine, if, thats...|[fine, thats, wa...|(13464,[0,74,105,...|\n",
      "| spam|England v Macedon...|       1.0|[england, v, mace...|[england, v, mace...|(13464,[4,30,33,5...|\n",
      "+-----+--------------------+----------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale the term frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"scaledFeatures\")\n",
    "idf_model = idf.fit(data)\n",
    "data = idf_model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----------+--------------------+--------------------+--------------------+--------------------+\n",
      "|label|             message|labelIndex|               words|      filtered_words|         rawFeatures|      scaledFeatures|\n",
      "+-----+--------------------+----------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  ham|Go until jurong p...|       0.0|[go, until, juron...|[go, jurong, poin...|(13464,[7,11,31,6...|(13464,[7,11,31,6...|\n",
      "|  ham|Ok lar... Joking ...|       0.0|[ok, lar..., joki...|[ok, lar..., joki...|(13464,[0,24,300,...|(13464,[0,24,300,...|\n",
      "| spam|Free entry in 2 a...|       1.0|[free, entry, in,...|[free, entry, 2, ...|(13464,[2,13,19,3...|(13464,[2,13,19,3...|\n",
      "|  ham|U dun say so earl...|       0.0|[u, dun, say, so,...|[u, dun, say, ear...|(13464,[0,69,80,1...|(13464,[0,69,80,1...|\n",
      "|  ham|Nah I don't think...|       0.0|[nah, i, don't, t...|[nah, think, goes...|(13464,[36,134,31...|(13464,[36,134,31...|\n",
      "| spam|FreeMsg Hey there...|       1.0|[freemsg, hey, th...|[freemsg, hey, da...|(13464,[10,67,140...|(13464,[10,67,140...|\n",
      "|  ham|Even my brother i...|       0.0|[even, my, brothe...|[even, brother, l...|(13464,[10,53,102...|(13464,[10,53,102...|\n",
      "|  ham|As per your reque...|       0.0|[as, per, your, r...|[per, request, 'm...|(13464,[127,185,4...|(13464,[127,185,4...|\n",
      "| spam|WINNER!! As a val...|       1.0|[winner!!, as, a,...|[winner!!, valued...|(13464,[1,46,121,...|(13464,[1,46,121,...|\n",
      "| spam|Had your mobile 1...|       1.0|[had, your, mobil...|[mobile, 11, mont...|(13464,[0,1,13,27...|(13464,[0,1,13,27...|\n",
      "|  ham|I'm gonna be home...|       0.0|[i'm, gonna, be, ...|[gonna, home, soo...|(13464,[18,43,117...|(13464,[18,43,117...|\n",
      "| spam|SIX chances to wi...|       1.0|[six, chances, to...|[six, chances, wi...|(13464,[8,16,37,8...|(13464,[8,16,37,8...|\n",
      "| spam|URGENT! You have ...|       1.0|[urgent!, you, ha...|[urgent!, won, 1,...|(13464,[13,30,46,...|(13464,[13,30,46,...|\n",
      "|  ham|I've been searchi...|       0.0|[i've, been, sear...|[searching, right...|(13464,[39,95,221...|(13464,[39,95,221...|\n",
      "|  ham|I HAVE A DATE ON ...|       0.0|[i, have, a, date...|[date, sunday, wi...|(13464,[555,1793,...|(13464,[555,1793,...|\n",
      "| spam|XXXMobileMovieClu...|       1.0|[xxxmobilemoviecl...|[xxxmobilemoviecl...|(13464,[30,109,11...|(13464,[30,109,11...|\n",
      "|  ham|Oh k...i'm watchi...|       0.0|[oh, k...i'm, wat...|[oh, k...i'm, wat...|(13464,[82,214,44...|(13464,[82,214,44...|\n",
      "|  ham|Eh u remember how...|       0.0|[eh, u, remember,...|[eh, u, remember,...|(13464,[0,2,49,13...|(13464,[0,2,49,13...|\n",
      "|  ham|Fine if thats th...|       0.0|[fine, if, thats...|[fine, thats, wa...|(13464,[0,74,105,...|(13464,[0,74,105,...|\n",
      "| spam|England v Macedon...|       1.0|[england, v, mace...|[england, v, mace...|(13464,[4,30,33,5...|(13464,[4,30,33,5...|\n",
      "+-----+--------------------+----------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=[\"scaledFeatures\"], outputCol=\"features\")\n",
    "data = assembler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|label|             message|labelIndex|               words|      filtered_words|         rawFeatures|      scaledFeatures|            features|\n",
      "+-----+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  ham|Go until jurong p...|       0.0|[go, until, juron...|[go, jurong, poin...|(13464,[7,11,31,6...|(13464,[7,11,31,6...|(13464,[7,11,31,6...|\n",
      "|  ham|Ok lar... Joking ...|       0.0|[ok, lar..., joki...|[ok, lar..., joki...|(13464,[0,24,300,...|(13464,[0,24,300,...|(13464,[0,24,300,...|\n",
      "| spam|Free entry in 2 a...|       1.0|[free, entry, in,...|[free, entry, 2, ...|(13464,[2,13,19,3...|(13464,[2,13,19,3...|(13464,[2,13,19,3...|\n",
      "|  ham|U dun say so earl...|       0.0|[u, dun, say, so,...|[u, dun, say, ear...|(13464,[0,69,80,1...|(13464,[0,69,80,1...|(13464,[0,69,80,1...|\n",
      "|  ham|Nah I don't think...|       0.0|[nah, i, don't, t...|[nah, think, goes...|(13464,[36,134,31...|(13464,[36,134,31...|(13464,[36,134,31...|\n",
      "| spam|FreeMsg Hey there...|       1.0|[freemsg, hey, th...|[freemsg, hey, da...|(13464,[10,67,140...|(13464,[10,67,140...|(13464,[10,67,140...|\n",
      "|  ham|Even my brother i...|       0.0|[even, my, brothe...|[even, brother, l...|(13464,[10,53,102...|(13464,[10,53,102...|(13464,[10,53,102...|\n",
      "|  ham|As per your reque...|       0.0|[as, per, your, r...|[per, request, 'm...|(13464,[127,185,4...|(13464,[127,185,4...|(13464,[127,185,4...|\n",
      "| spam|WINNER!! As a val...|       1.0|[winner!!, as, a,...|[winner!!, valued...|(13464,[1,46,121,...|(13464,[1,46,121,...|(13464,[1,46,121,...|\n",
      "| spam|Had your mobile 1...|       1.0|[had, your, mobil...|[mobile, 11, mont...|(13464,[0,1,13,27...|(13464,[0,1,13,27...|(13464,[0,1,13,27...|\n",
      "|  ham|I'm gonna be home...|       0.0|[i'm, gonna, be, ...|[gonna, home, soo...|(13464,[18,43,117...|(13464,[18,43,117...|(13464,[18,43,117...|\n",
      "| spam|SIX chances to wi...|       1.0|[six, chances, to...|[six, chances, wi...|(13464,[8,16,37,8...|(13464,[8,16,37,8...|(13464,[8,16,37,8...|\n",
      "| spam|URGENT! You have ...|       1.0|[urgent!, you, ha...|[urgent!, won, 1,...|(13464,[13,30,46,...|(13464,[13,30,46,...|(13464,[13,30,46,...|\n",
      "|  ham|I've been searchi...|       0.0|[i've, been, sear...|[searching, right...|(13464,[39,95,221...|(13464,[39,95,221...|(13464,[39,95,221...|\n",
      "|  ham|I HAVE A DATE ON ...|       0.0|[i, have, a, date...|[date, sunday, wi...|(13464,[555,1793,...|(13464,[555,1793,...|(13464,[555,1793,...|\n",
      "| spam|XXXMobileMovieClu...|       1.0|[xxxmobilemoviecl...|[xxxmobilemoviecl...|(13464,[30,109,11...|(13464,[30,109,11...|(13464,[30,109,11...|\n",
      "|  ham|Oh k...i'm watchi...|       0.0|[oh, k...i'm, wat...|[oh, k...i'm, wat...|(13464,[82,214,44...|(13464,[82,214,44...|(13464,[82,214,44...|\n",
      "|  ham|Eh u remember how...|       0.0|[eh, u, remember,...|[eh, u, remember,...|(13464,[0,2,49,13...|(13464,[0,2,49,13...|(13464,[0,2,49,13...|\n",
      "|  ham|Fine if thats th...|       0.0|[fine, if, thats...|[fine, thats, wa...|(13464,[0,74,105,...|(13464,[0,74,105,...|(13464,[0,74,105,...|\n",
      "| spam|England v Macedon...|       1.0|[england, v, mace...|[england, v, mace...|(13464,[4,30,33,5...|(13464,[4,30,33,5...|(13464,[4,30,33,5...|\n",
      "+-----+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "\n",
    "training_data = training_data.select(\"labelIndex\", \"features\")\n",
    "test_data = test_data.select(\"labelIndex\", \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data count: 4503\n",
      "Test data count: 1071\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training data count: {training_data.count()}\")\n",
    "print(f\"Test data count: {test_data.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"labelIndex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = lr.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_predictions = lr_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"labelIndex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = dt.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_predictions = dt_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"labelIndex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = rf.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predictions = rf_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes(featuresCol=\"features\", labelCol=\"labelIndex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = nb.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_predictions = nb_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9803921568627451\n"
     ]
    }
   ],
   "source": [
    "lr_accuracy = evaluator.evaluate(lr_predictions)\n",
    "print(f\"Logistic Regression Accuracy: {lr_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.9197012138188608\n"
     ]
    }
   ],
   "source": [
    "dt_accuracy = evaluator.evaluate(dt_predictions)\n",
    "print(f\"Decision Tree Accuracy: {dt_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8627450980392157\n"
     ]
    }
   ],
   "source": [
    "rf_accuracy = evaluator.evaluate(rf_predictions)\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.9140989729225023\n"
     ]
    }
   ],
   "source": [
    "nb_accuracy = evaluator.evaluate(nb_predictions)\n",
    "print(f\"Naive Bayes Accuracy: {nb_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Number of Trees: 50\n",
      "Best Max Depth: 10\n",
      "Best Max Bins: 32\n",
      "Random Forest Accuracy: 0.8786181139122315\n"
     ]
    }
   ],
   "source": [
    "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [10, 50]).addGrid(rf.maxDepth, [5, 10]).addGrid(rf.maxBins, [32, 64]).build()\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"labelIndex\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "\n",
    "crossval = CrossValidator(\n",
    "    estimator=rf,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=5,  \n",
    "    seed=42\n",
    ")\n",
    "\n",
    "cvModel = crossval.fit(training_data)\n",
    "\n",
    "bestModel = cvModel.bestModel\n",
    "accuracy = evaluator.evaluate(cvModel.transform(test_data))\n",
    "\n",
    "print(f\"Best Number of Trees: {bestModel.getNumTrees}\")\n",
    "print(f\"Best Max Depth: {bestModel.getMaxDepth()}\")\n",
    "print(f\"Best Max Bins: {bestModel.getMaxBins()}\")\n",
    "print(f\"Random Forest Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Classification Method  Accuracy\n",
      "0   Logistic Regression  0.980392\n",
      "1         Decision Tree  0.919701\n",
      "2         Random Forest  0.862745\n",
      "3           Naive Bayes  0.914099\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Classification Method': ['Logistic Regression', 'Decision Tree', 'Random Forest', 'Naive Bayes'],\n",
    "    'Accuracy': [0.9803921568627451, 0.9197012138188608, 0.8627450980392157, 0.9140989729225023]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the method with the best accuracy is \"Logistic Regression\", so it is the most suitable method. However the method with the worst accuracy was \"Random Forest\". \"Decision Tree\" and \"Naive Bayes\" also have good result with an accuracy bigger than 0.90, but they would need more tuning to get better results. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
